---
title: "Hypothesis Testing with scipy.stats"
author: "Isabelle Perez"
toc: true
number-sections: true
highlight-style: pygments
format: 
  html: 
    code-fold: true
    html-math-method: katex
  pdf: 
    geometry: 
      - top=30mm
      - left=20mm
##  docx: default
--- 

This section was written by Isabelle Perez. 


## Introduction  
The package `scipy.stats` is a subpackage of `Scipy` and contains many methods useful
for statistics such as probability distributions, summary statistics, statistical tests,
etc. The focus of this presentation will be on some of the many hypothesis tests that can 
be easily conducted using `scipy.stats` and will provide examples of situations in 
which they may be useful.  

Firstly, ensure `scipy.stats` is installed by using 
`pip install scipy.stats` or `pip3 install scipy.stats`, depending on what version of python you are using. 

## Basic Statistical Hypothesis Tests 
### Two-sample t-test 

| H~0~: $\mu_1 = \mu_2$  
| H~1~: $\mu_1 \neq$ or $>$ or $<$ $\mu_2$   

&NewLine; 

**Code:** `scipy.stats.ttest_ind(sample_1, sample_2)`  

**Assumptions:** Observations are independent and identically distributed (i.i.d), 
normally distributed, and the two samples have equal variances. 

**Optional Parameters:**

* `nan_policy` can be set to `propagate` (return `nan`), `raise` (raise `ValueError`),
or `omit`(ignore null values).
* `alternative` can be `two-sided` (default), `less`, or `greater`. 
* `equal_var` is a boolean representing whether the variances of the two samples are 
equal (default is True). 
* `axis` defines the axis along which the statistic should be computed (default is 0). 

**Returns:** The t-statisic, a corresponding p-value, and the degrees of freedom. 

### Paired t-test 

| H~0~: $\mu_1 = \mu_2$
| H~1~: $\mu_1 \neq$ or $>$ or $<$ $\mu_2$  
 
&NewLine; 

**Code:** `scipy.stats.ttest_rel(sample_1, sample_2)` 

**Assumptions:** Observations are i.i.d, normally distributed, and related, 
and the two samples have equal variances. The input arrays must also be 
of the same size since the observations are paired.  

**Optional Parameters:** Can use `nan_policy` or `alternative`. 

**Returns:** The t-statisic, a corresponding p-value, and the degrees of freedom. 
Also has a method called `confidence_interval` with input parameter `confidence_level`
that returns a tuple with the confidence interval around the difference in 
population means of the two samples.  

### ANOVA 

| H~0~: $\mu_1 = \mu_2 = ... = \mu_n$
| H~1~: at least two $\mu_i$ are not equal  

&NewLine; 

**Code:** `scipy.stats.f_oneway(sample_1, sample_2, ..., sample_n)`

**Assumptions:** Samples are i.i.d., normally distributed, and the samples have
equal variances. 

**Errors:**  

* Raises `ConstantInputWarning` if all values in each of the inputs are 
identical. 
* Raises `DegenerateDataWarning` if any input has length $0$ or all inputs
have length $1$. 

**Returns:** The F-statistic and a corresponding p-value. 

### Example: Comparison of Mean Response Times by Borough  
Looking at the 2022-2023 rodent sighting data from the NYC 311 Service Requests, there are many
ways a two-sample t-test may be useful. For example, we can consider samples drawn from different
boroughs and perform this hypothesis test to identify whether their mean response times differ. 
If so, this may suggest that some boroughs are being underserviced.  
```{python} 
import pandas as pd 
import numpy as np 
import scipy.stats   

# read in file 
df = pd.read_csv('rodent_2022-2023.csv')  

# data cleaning - change dates to timestamp object
df['Created Date'] = pd.to_datetime(df['Created Date'])
df['Closed Date'] = pd.to_datetime(df['Closed Date'])

# add column Response Time 
df['Response Time'] = df['Closed Date'] - df['Created Date']

# convert data to total seconds
df['Response Time'] = df['Response Time'].apply(lambda x: x.total_seconds() / 3600)    
``` 

Since the two-sample t-test assumes the data is drawn from a normal distribution, we need to
ensure the samples we are comparing are normally distributed. According to the Central Limit theorem,
the distribution of sample means from repeated samples of a population will be roughly normal. 
Therefore, we can take 100 samples of each borough's response times, measure the mean of each sample,
and perform the hypothesis test on the arrays of sample means. 
```{python}
import matplotlib.pyplot as plt 

# select Bronx and Queens boroughs 
df_mhtn = df[df['Borough'] == 'MANHATTAN']['Response Time'] 
df_queens = df[df['Borough'] == 'QUEENS']['Response Time']  

mhtn_means = []
queens_means = []

# create samples of sampling means 
for i in range(100): 
  sample1 = df_mhtn.sample(1000, replace = True)
  mhtn_means.append(sample1.mean())

  sample2 = df_queens.sample(1000, replace = True) 
  queens_means.append(sample2.mean())  

# plot distribution of sample means for Manhattan
plt.hist(mhtn_means)
plt.xlabel('Mean Response Times for Manhattan')
plt.ylabel('Value Counts')
plt.show()

# plot distribution of sample means for Queens 
plt.hist(queens_means) 
plt.xlabel('Mean Response Times for Queens')
plt.ylabel('Value Counts')
plt.show() 
```  

We also need to check if the variances of the two samples are equal. 
```{python}
# convert to numpy array 
mhtn_means = np.array(mhtn_means)
queens_means = np.array(queens_means)

print('Mean, variance for Manhattan', (mhtn_means.mean(), mhtn_means.std() ** 2))
print('Mean, variance for Queens:', (queens_means.mean(), queens_means.std() ** 2))
```
Since the ratio of the variances is less than $2$, it is safe to assume equal variances.  

```{python}
result_1 = scipy.stats.ttest_ind(mhtn_means, queens_means, equal_var = True)

print('t-statistic:', result_1.statistic)
print('p-value:', result_1.pvalue) 
print('degrees of freedom:', result_1.df) 
``` 
At an alpha level of $0.05$, the p-value allows us to reject the null hypothesis
and conclude that there is a statistically significant difference in the mean of 
sample means drawn from rodent sighting response times for Manhattan compared to Queens. 

```{python}
result_2 = scipy.stats.ttest_ind(mhtn_means, queens_means, equal_var = True, alternative = 'less') 

print('t-statistic:', result_2.statistic)
print('p-value:', result_2.pvalue) 
print('degrees of freedom:', result_2.df) 
```
We can also set the alternative equal to `less` to test if the mean of sample means
drawn from the Manhattan response times is less than that of sample means drawn from
Queens response times. At the alpha level of $0.05$, we can also reject this null
hypothesis and conclude that the mean of sample means is less for Manhattan than 
it is for Queens. 

## Normality 
### Shapiro-Wilk Test 

| H~0~: data is drawn from a normal distribution  
| H~1~: data is not drawn from a normal distribution     

&NewLine; 

**Code:** `scipy.stats.shapiro(sample)` 

**Assumptions:** Observations are i.i.d. 

**Returns:** The test statistic and corresponding p-value. 

* More appropriate for smaller sample sizes ($<50$). 
* The closer the test statistic is to $1$, the closer it is to a normal 
distribution, with $1$ being a perfect match.   

### NormalTest 

| H~0~: data is drawn from a normal distribution  
| H~1~: data is not drawn from a normal distribution   

&NewLine; 

**Code:** `scipy.stats.normaltest(sample)`  

**Assumptions:** Observations are i.i.d. 

**Optional Parameters:** Can use `nan_policy`. 

**Returns:** The test-statistic $s^2 + k^2$, where $s^2$ is from the `skewtest`
and $k$ is from the `kurtosistest`, and a corresponding p-value

This test is based on D'Agostino and Pearson's test which combines skew
and kurtosis (heaviness of the tail or how much data resides in the tails). 
The test compares the skewness and kurtosis of the sample to that of a normal 
distribution, which are $0$ and $3$, respectively. 

### Example: Distribution of Response Times 
It can be useful to identify the distribution of a population because it gives
us the ability to summarize the data more efficiently. We can identify whether
or not the distribution of a sample of response times from the rodent sighting
dataset is normal by conducting a normality test using `scipy.stats`. 

```{python}
# take a sample from Response Time column 
resp_time_samp = df['Response Time'].sample(10000, random_state = 0)  

results_2 = scipy.stats.normaltest(resp_time_samp, nan_policy = 'propagate')

print('test statistic:', results_2.statistic) 
print('p-value:', results_2.pvalue)
``` 
Because there are null values in the sample data, if we set the `nan_policy` 
to `propagate`, both the test statistic and p-value will return as `nan`. 
If we still want to obtain results when there is missing data, we must set the
`nan_policy` to `omit`. 

```{python}
results_3 = scipy.stats.normaltest(resp_time_samp, nan_policy = 'omit') 

print('test statistic:', results_3.statistic) 
print('p-value:', results_3.pvalue)
```
At an alpha level of $0.05$, the p-value allows us to reject the null hypothesis
and conclude that the data is not drawn from a normal distribution. We can further
show this by plotting the data in a histogram. 

```{python}
bins = [i for i in range(int(resp_time_samp.min()), int(resp_time_samp.max()), 300)]

plt.hist(resp_time_samp, bins = bins)
plt.xlabel('Response Times')
plt.ylabel('Value Counts')
plt.show()
``` 

## Correlation   
### Pearson's Correlation     

| H~0~: the correlations is $0$
| H~1~: the correlations is $\neq$, $<$, or $> 0$ 

&NewLine; 

**Code:** `scipy.stats.pearsonr(sample_1, sample_2)`

**Assumptions:** Observations are i.i.d, normally distributed, and the two samples
have equal variances. 

**Optional Parameters:** Can use `alternative`. 

**Errors:** 

* Raises `ConstantInputWarning` if either input has all constant values. 
* Raises `NearConstantInputWarning` if 
`np.linalg.norm(x - mean(x)) < 1e-13 * np.abs(mean(x))`. 

**Returns:** The correlation coefficient and a corresponding p-value. It also 
has the `confidence_interval` method. 

### Chi-Squared Test 

| H~0~: the two variables are independent of one another
| H~1~: a dependency exists between the two variables 

&NewLine; 

**Code:** `scipy.stats.chi2_contingency(table)` 

**Assumptions:** The cells in the table contain frequencies, the levels of each
variable are mutually exclusive, and observations are independent.  

**Returns:** The test statistic, a corresponding p-value, the degrees of freedom, 
and an array of expected frequencies from the table. 

* `dof = table.size - sum(table.shape) + table.ndim - 1` 

### Example: Analyzing the Relationship Between Borough and Response Time 
```{python}
# create frequency table 
freq_table = pd.crosstab(df.Borough, df.Descriptor, margins = True) 

freq_table

results_chi2 = scipy.stats.chi2_contingency(freq_table)

print('test statistic:', results_chi2.statistic)
print('p-value:', results_chi2.pvalue)
print('degrees of freedom:', results_chi2.dof) 
``` 

## Nonparametric Hypothesis Tests   
### Mann-Whitney U Test  

| H~0~: distribution of sample 1 $=$ distribution of sample 2
| H~1~: distribution of sample 1 $\neq$ or $>$ or $<$ distribution of sample 2   

&NewLine; 

**Code:** `scipy.stats.mannwhitneyu(sample_1, sample_2)` 

**Assumptions:** Observations are i.i.d. and are ordinal.  

**Optional Parameters:** 

:::{}
* `alternative` can allow us to test if one sample has a distribution that is 
stochastically less than or greater than that of the second sample.   
* Can use `nan_policy`. 
* `method` selects how the p-value is calculated and can be set to 
`asymptotic`, `exact`, or `auto`. 
  + `asymptotic` corrects for ties and compares the standardized test statistic
  to the normal distribution. 
  + `exact` does not correct for ties and computes the exact p-value.
  + `auto` is the default and chooses exact when there are no ties and the 
  size of one sample is $<=8$, `asymptotic` otherwise. 
::: 

**Returns:** The Mann-Whitney U Statistic corresponding with the first sample 
and a corresponding p-value. 

:::{}
* The statistic corresponding to the second sample is not returned but can 
be calculated as `sample_1.shape * sample_2.shape - U1` where `U1` is the 
test statistic associated with `sample_1`. 
* For large sample sizes, the distribution can be assumed to be approximately
normal, so the statisic can be measured as $z = \frac{U-\mu_{U}}{\sigma_{U}}$.
* To adjust for ties, the standard deviation is calculated as follows: 

$\sigma_{U} = \sqrt{\frac{n_{1}n_{2}}{12}((n + 1) - \frac{\sum_{k = 1}^{K}(t^{3}_{k} - t_{k})}{n(n - 1)})}$, where $t_{k}$ is the number of ties. 
::: 

## References 
<https://docs.scipy.org/doc/scipy/reference/stats.html>
